# -*- coding: utf-8 -*-
"""FAANG Stocks Covid-19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FPyh0zvMRl6rQPpKd2V1zUBA1UBthMMb

# **FAANG Stocks Covid -19 - Data Science in Everyday Industries - Part 2**

#### **1. Problem Statement and Data Collection**

***Can we predict the stock prices of FAANG companies during the COVID-19 pandemic based on historical trends and pandemic-related economic factors?***

Related Word Report - https://yotescollegeofidaho-my.sharepoint.com/:w:/g/personal/bathigesuthira_desil_yotes_collegeofidaho_edu/EdvjTupZdNhKl600w2jRsyMBnHMjAqBUbRCIVJWoy6ahdA?e=osfU7K

Dataset from Kaggle - https://www.kaggle.com/datasets/parisrohan/faang-stocks-covid190101202004012022/data

#### **2. Data Cleaning and Preprocessing**
"""

# Importing the packaages
import pandas as pd
import numpy as np
import io
import matplotlib.pyplot as plt
import seaborn as sns

!pip install pandasql
from pandasql import sqldf

# Loading the dataset and Checking for NA/missing values
df = pd.read_csv('/content/faang_stocks_pandemic_data.csv').dropna(axis=1, how='all')
df.isna().sum()

# It seems like all rows have no NA or misssing values.

# Convert the "Unnamed: 0" column to an index column and Rename as "Index".
df = df.rename(columns={'Unnamed: 0': 'Index'})
df = df.set_index('Index')

# Previewing the dataset
df.head()

# Checking the number of columns
df.shape

# The "Date" column will be converted into a datetime format to facilitate time-based grouping, sorting.
df["Date"] = pd.to_datetime(df["Date"])

# Daily Price Range: Calculated as High - Low to assess daily volatility.
daily_price_range = df['High'] - df['Low']
df['Daily_Price_Range'] = daily_price_range
df.head()

# Percent Change: ((Close - Open) )/Open  Ã—100 to measure daily returns.
percent_change = ((df['Close'] - df['Open']) / df['Open']) * 100
df['Percent_Change'] = percent_change
df.head()

# Moving Averages: Short-term (e.g., 5-day) and long-term (e.g., 30-day) moving averages for trends analysis.
df['5_Day_MA'] = df['Close'].rolling(window=5).mean()
df['30_Day_MA'] = df['Close'].rolling(window=30).mean()

# it appears that computing short term and long term averages for certain dates is not feasible, and we would replace those NaN values with 0.00 floats.
df['5_Day_MA'] = df['5_Day_MA'].fillna(0)
df['30_Day_MA'] = df['30_Day_MA'].fillna(0)

df.head(50)

# Cumulative Volume: Running total of the traded volume for each stock.
df['Cumulative_Volume'] = df.groupby('Name')['Volume'].cumsum()
df.head()

# Company-Specific Filtering: Data will be filtered by the "Name" column to enable focused analysis for individual FAANG companies if necessary.
# Facebook
filtered_df_facebook = df[df['Name'] == 'Facebook']
filtered_df_facebook.head(6)

# Apple
filtered_df_apple = df[df['Name'] == 'Apple']
filtered_df_apple.head(6)

# Amazon
filtered_df_amazon = df[df['Name'] == 'Amazon']
filtered_df_amazon.head(6)

# Netflix
filtered_df_netflix = df[df['Name'] == 'Netflix']
filtered_df_netflix.head(6)

# Google
filtered_df_google = df[df['Name'] == 'Google']
filtered_df_google.head(6)

# Plotting boxplots for numerical columns like "High," "Low," "Open," "Close," and "Volume."
numerical_columns = ['High', 'Low', 'Open', 'Close', 'Volume']
plt.figure(figsize=(12, 6))
for i, column in enumerate(numerical_columns, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(x=df['Name'], y=df[column])

# Using statistical methods such as the interquartile range (IQR) to detect extreme values.

# Select numerical columns to analyze
numerical_cols = ['High', 'Low', 'Open', 'Close', 'Volume']

# Loop through each numerical column to calculate and treat outliers
for col in numerical_cols:
    # Calculate Q1, Q3, and IQR
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    # Define lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Detect outliers
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"Outliers detected in {col}: {len(outliers)}")

    # Treat outliers: Capping
    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)

# Check if outliers exist in each numerical columns
for col in numerical_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"Outliers detected in {col}: {len(outliers)}")

# Checking the number of columns
df.shape

"""#### **3. Exploratory Data Analysis**"""

# Descriptive statistics for all columns
df.describe()

# Distribution of closing prices
df['Close'].hist(bins=50, edgecolor='black', alpha=0.7)
plt.title('Distribution of Closing Prices Across FAANG Companies')
plt.xlabel('Close Price')
plt.ylabel('Frequency')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# This graph shows the distribution of the closing prices of FAANG companies.
# It helps identify the range and frequency of closing prices during the pandemic.

# Distribution of trading volumes
df['Volume'].hist(bins=50, edgecolor='black', alpha=0.7)
plt.title('Distribution of Trading Volumes Across FAANG Companies')
plt.xlabel('Volume')
plt.ylabel('Frequency')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# This graph shows how trading volumes were distributed. It helps identify high-activity days and overall trading patterns.

# Distribution of High prices
df['High'].plot(kind='hist', bins=20, title='Distribution of High Prices Across FAANG Companies')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

# This graph shows the distribution of the highest prices recorded daily, offering insight into stock price peaks.

# Distribution of Low prices
df['Low'].plot(kind='hist', bins=20, title='Distribution of Low Prices Across FAANG Companies')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

# This graph illustrates the distribution of daily lowest prices, providing insight into stock price troughs.

# High vs Low
df.plot(kind='scatter', x='High', y='Low', s=32, alpha=.8)
plt.title('Relationship Between Daily High and Low Prices')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

# This scatter plot shows the correlation between the daily high and low prices, indicating price volatility.

# Open vs Close
df.plot(kind='scatter', x='Open', y='Close', s=32, alpha=.8)
plt.title('Relationship Between Daily Opening and Closing Prices')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

# This scatter plot shows the relationship between opening and closing prices, highlighting intraday stock performance.

# Trends in High Prices Over Time
df['High'].plot(kind='line', figsize=(8, 4), title='High Prices Over Time')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

# This line graph shows the trend of daily high prices over time, revealing how stock highs evolved.

def _plot_series(series, series_name, i):
    """Plots a time series with a specific color."""
    ax = series.plot(x='Date', y='High', label=series_name, color=f'C{i}')

# Trends in High Prices by Date for Each Company
fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
df_sorted = df.sort_values('Date', ascending=True)
for i, (series_name, series) in enumerate(df_sorted.groupby('Name')):
    _plot_series(series, series_name, i)
fig.legend(title='Name', bbox_to_anchor=(1, 1), loc='upper left')
sns.despine(fig=fig, ax=ax)
plt.xlabel('Date')
plt.ylabel('High')
plt.title('High Prices Over Time by FAANG Company')
plt.show()

# This graph shows the trends in high prices for each FAANG company over the given time frame, enabling comparisons.

# Distribution of Close Prices by Company
figsize = (12, 1.2 * len(df['Name'].unique()))
plt.figure(figsize=figsize)
sns.violinplot(df, x='Close', y='Name', inner='box', palette='Dark2')
sns.despine(top=True, right=True, bottom=True, left=True)
plt.title('Distribution of Close Prices Across FAANG Companies')
plt.show()

# This violin plot shows the distribution of closing prices for each company, highlighting variability and medians.

# Trends in Open Prices by Date for Each Company
fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
for i, (series_name, series) in enumerate(df_sorted.groupby('Name')):
    _plot_series(series, series_name, i)
fig.legend(title='Name', bbox_to_anchor=(1, 1), loc='upper left')
sns.despine(fig=fig, ax=ax)
plt.xlabel('Date')
plt.ylabel('Open')
plt.title('Open Prices Over Time by FAANG Company')
plt.show()

# This graph shows how opening prices for FAANG stocks changed over the pandemic, revealing trends.

# Trends in Close Prices by Date for Each Company
fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
for i, (series_name, series) in enumerate(df_sorted.groupby('Name')):
    _plot_series(series, series_name, i)
fig.legend(title='Name', bbox_to_anchor=(1, 1), loc='upper left')
sns.despine(fig=fig, ax=ax)
plt.xlabel('Date')
plt.ylabel('Close')
plt.title('Close Prices Over Time by FAANG Company')
plt.show()

# This graph tracks the closing prices for FAANG companies over time, helping to identify key price trends.

# Close vs Volume
df.plot(kind='scatter', x='Close', y='Volume', s=32, alpha=.8)
plt.title('Relationship Between Closing Prices and Trading Volumes')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

# This scatter plot shows how trading volume correlates with closing prices, potentially indicating market activity levels.

"""#### **4. Insights and Interpretation**

***Refer to the word report for the explanation of insights, and interpretations derived from the data, and relevance of insights to the problem statement.***

Related Word Report - https://yotescollegeofidaho-my.sharepoint.com/:w:/g/personal/bathigesuthira_desil_yotes_collegeofidaho_edu/EdvjTupZdNhKl600w2jRsyMBnHMjAqBUbRCIVJWoy6ahdA?e=osfU7K

#### **5. Proposed Modeling Approach**

***Refer to the word report for details about the prediction model, and here is the code to train the model on the dataset and predict for each company.****
"""

# Importing TensorFlow ML packages
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Selecting features and target
features = ['Open', 'High', 'Low', 'Volume', '5_Day_MA', '30_Day_MA', 'Daily_Price_Range', 'Percent_Change'] # Corrected the typo here
X = df[features]
y = df['Close']

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the data for LSTM
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
linear_preds = linear_model.predict(X_test)
linear_mse = mean_squared_error(y_test, linear_preds)
linear_r2 = r2_score(y_test, linear_preds)
print("Linear Regression:")
print("MSE:", linear_mse)
print("R2 Score:", linear_r2)

# Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42, n_estimators=100)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)
rf_mse = mean_squared_error(y_test, rf_preds)
rf_r2 = r2_score(y_test, rf_preds)
print("\nRandom Forest Regressor:")
print("MSE:", rf_mse)
print("R2 Score:", rf_r2)

# LSTM Model
X_train_lstm = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_lstm = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

lstm_model = Sequential()
lstm_model.add(LSTM(50, return_sequences=True, input_shape=(1, X_train_scaled.shape[1])))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(50, return_sequences=False))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(1))

lstm_model.compile(optimizer='adam', loss='mean_squared_error')
lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, verbose=1)
lstm_preds = lstm_model.predict(X_test_lstm)
lstm_mse = mean_squared_error(y_test, lstm_preds)
lstm_r2 = r2_score(y_test, lstm_preds)

print("\nLSTM Model:")
print("MSE:", lstm_mse)
print("R2 Score:", lstm_r2)

# Summary of results
results = {
    'Model': ['Linear Regression', 'Random Forest Regressor', 'LSTM'],
    'MSE': [linear_mse, rf_mse, lstm_mse],
    'R2 Score': [linear_r2, rf_r2, lstm_r2]
}
results_df = pd.DataFrame(results)
print("\nModel Performance Summary:")
print(results_df)

# Best model selection
best_model = results_df.loc[results_df['R2 Score'].idxmax()]
print("\nBest Model:")
print(best_model)

# Predict stock prices for each company if a pandemic like COVID-19 happened again
def predict_pandemic_prices(df, model, scaler):
    # Simulate pandemic-like conditions by using a subset of features with adjustments
    pandemic_features = df[features].copy()
    pandemic_features['Volume'] *= 1.5  # Assume increased trading activity
    pandemic_features['Percent_Change'] *= 1.2  # Assume higher price changes due to volatility

    # Scale the features
    scaled_features = scaler.transform(pandemic_features)

    if isinstance(model, Sequential):
        scaled_features = np.reshape(scaled_features, (scaled_features.shape[0], 1, scaled_features.shape[1]))

    # Predict prices
    predicted_prices = model.predict(scaled_features)
    return predicted_prices

# Here I would choose the best model for prediction and plot with it.
if best_model['Model'] == 'Linear Regression':
    final_model = linear_model
elif best_model['Model'] == 'Random Forest Regressor':
    final_model = rf_model
else:
    final_model = lstm_model

predicted_prices = predict_pandemic_prices(df, final_model, scaler)
df['Predicted_Pandemic_Prices'] = predicted_prices

# Plot the predictions for all FAANG companies
plt.figure(figsize=(12, 6))
for company, group in df.groupby('Name'):
    plt.plot(group['Date'], group['Predicted_Pandemic_Prices'], label=company)
plt.title('Predicted Pandemic Prices for FAANG Companies')
plt.xlabel('Date')
plt.ylabel('Predicted Prices')
plt.legend()
plt.grid(axis='both', linestyle='--', alpha=0.7)
plt.show()

# Plot the predictions for each company seperate plots
plt.figure(figsize=(12, 6))
for company, company_data in df.groupby('Name'):
    plt.plot(company_data['Date'], company_data['Close'], label=f'{company} Actual Prices')
    plt.plot(company_data['Date'], company_data['Predicted_Pandemic_Prices'], label=f'{company} Predicted Prices')

plt.title('Actual vs Predicted Prices for Each Company')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()


# Display predicted prices limit one for each comapny
print("\nPredicted Prices for Each Company:")
print(df.groupby('Name')['Predicted_Pandemic_Prices'].last())